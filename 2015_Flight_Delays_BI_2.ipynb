{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTexXF6mMkBM"
   },
   "source": [
    "# Business Intelligence II - Group 2\n",
    "Created by: Marvin Bathke, Tjorven Beckedorf, Kevin Tiet and Cem Yesil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8lb-OVqNE3b"
   },
   "source": [
    "## Dataset: 2015 Flight Delays and Cancellations\n",
    "Link to data source: https://www.kaggle.com/datasets/usdot/flight-delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sATlojBrMhty"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import folium as fl\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZofxJOpZSFRt",
    "outputId": "38c0bf91-21d1-48f3-9bf0-82f027c0208e"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'airlines.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9636\\2079482190.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mairlines_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'airlines.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mairports_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'airports.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m flights_data = pd.read_csv('flights.csv', dtype={\"SCHEDULED_DEPARTURE\": \"string\",\n\u001B[0;32m      4\u001B[0m                                                        \u001B[1;34m\"DEPARTURE_TIME\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m\"string\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m                                                        \u001B[1;34m\"WHEELS_OFF\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m\"string\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    676\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    677\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 678\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    679\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    680\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 575\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    576\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    577\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    930\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    931\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 932\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    933\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    934\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1214\u001B[0m             \u001B[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1215\u001B[0m             \u001B[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1216\u001B[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001B[0m\u001B[0;32m   1217\u001B[0m                 \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1218\u001B[0m                 \u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    784\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    785\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 786\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    787\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    788\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'airlines.csv'"
     ]
    }
   ],
   "source": [
    "airlines_data = pd.read_csv('airlines.csv')\n",
    "airports_data = pd.read_csv('airports.csv')\n",
    "flights_data = pd.read_csv('flights.csv', dtype={\"SCHEDULED_DEPARTURE\": \"string\",\n",
    "                                                       \"DEPARTURE_TIME\": \"string\",\n",
    "                                                       \"WHEELS_OFF\": \"string\",\n",
    "                                                       \"WHEELS_ON\": \"string\",\n",
    "                                                       \"SCHEDULED_ARRIVAL\": \"string\",\n",
    "                                                       \"ARRIVAL_TIME\": \"string\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DPFIAZgS-Vk"
   },
   "source": [
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKG7rDmISZHR"
   },
   "outputs": [],
   "source": [
    "airlines_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxXEQ8HlTHCS"
   },
   "outputs": [],
   "source": [
    "airlines_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTDTMrXbTLlQ"
   },
   "outputs": [],
   "source": [
    "airlines_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "8q-YelJsSnc8"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "airports_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHln1GBUTRf1"
   },
   "outputs": [],
   "source": [
    "airports_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnC9ne_gTULO"
   },
   "outputs": [],
   "source": [
    "airports_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coOYzKT3SumW"
   },
   "outputs": [],
   "source": [
    "flights_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fju0A_N1Swyo"
   },
   "outputs": [],
   "source": [
    "flights_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxbZ4qICTdyM"
   },
   "outputs": [],
   "source": [
    "flights_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1-RnlnOWxEI"
   },
   "source": [
    "### Data Description\n",
    "\n",
    "Data Description for the flights table:\n",
    "- **YEAR**: The year the flight arrived.\n",
    "- **MONTH**: The month the flight arrived.\n",
    "- **DAY**: The day the flight arrived.\n",
    "- **DAY_OF_WEEK**: The weekday the flight arrived encoded in int from 1 to 7.\n",
    "- **AIRLINE**: The IATA_CODE of the airline of the flight.\n",
    "- **FLIGHT_NUMBER**: Number of the flight.\n",
    "- **TAIL_NUMBER**: An identification number for airplanes. \n",
    "- **ORIGIN_AIRPORT**: The IATA_CODE of the airport the airplane is scheduled to depart.\n",
    "- **DESTINATION_AIRPORT**: The IATA_CODE of the airport the airplane is scheduled to land.\n",
    "- **SCHEDULED_DEPARTURE**: Scheduled departure time encoded as HHMM String\n",
    "- **DEPARTURE_TIME**: The time it takes from the closing of the gate to the actual wheels off. Also encoded as HHMM String.\n",
    "- **DEPARTURE_DELAY**: The delay of the departure in min between the real and the planned departure.\n",
    "- **TAXI_OUT**: The time duration elapsed between departure from the origin airport gate and wheels off.\n",
    "- **WHEELS_OFF**: The actual time the airplane departed as HHMM String.\n",
    "- **SCHEDULED_TIME**: The planned time the flight trip is needed.\n",
    "- **ELAPSED_TIME**: The form TAXI_IN to TAXI_OUT.\n",
    "- **AIR_TIME**: The duration between wheels_on and wheels_off.\n",
    "- **DISTANCE**: Distance between the two airports.\n",
    "- **WHEELS_ON**: The time point that the aircraft's wheels touch on the ground.\n",
    "- **TAXI_IN**: The time duration elapsed between wheels-on and gate arrival at the destination airport.\n",
    "- **SCHEDULED_ARRIVAL**: Planned arrival time as HHMM String.\n",
    "- **ARRIVAL_TIME**: The time of WHEELS_IN + TAXI_IN\n",
    "- **ARRIVAL_DELAY**: The delay of the arrival in min between the real and the scheduled arrival.\n",
    "- **DIVERTED**: Aircraft got diverted to another airport. 0 = no; 1 = yes\n",
    "- **CANCELLED**: Flight got cancelled. 0 = no ; 1 = yes.\n",
    "- **CANCELLATION_REASON**: Reason why the flight is cancelled. A= Airline/Carrier, B= Weather, C= National Air System, D = Security\n",
    "- **AIR_SYSTEM_DELAY**: Delay caused by air system in minutes\n",
    "- **SECURITY_DELAY**: Delay caused by security in minutes\n",
    "- **AIRLINE_DELAY**:  Delay caused by the airline in minutes\n",
    "- **LATE_AIRCRAFT_DELAY**: Delay caused by aircraft in minutes.\n",
    "- **WEATHER_DELAY**: Delay caused by weather in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPmjJJFMWp3_"
   },
   "outputs": [],
   "source": [
    "flights_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHsWnwWVT0AU"
   },
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vm5ucx3jagnm"
   },
   "source": [
    "### 3.1 Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbvT0v4WRWdQ"
   },
   "source": [
    "Convert all columns to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdriiBQlRMYZ"
   },
   "outputs": [],
   "source": [
    "flights_data.columns = map(str.lower, flights_data.columns)\n",
    "airlines_data.columns = map(str.lower, airlines_data.columns)\n",
    "airports_data.columns = map(str.lower, airports_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcZE9WFhs2UB"
   },
   "source": [
    "Firstly, make the date columns to an actual date. Using datetime and a dateformat is more convenient to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVnGIODlZ1OS"
   },
   "outputs": [],
   "source": [
    "flights_data[\"date\"] = pd.to_datetime(flights_data[[\"year\", \"month\", \"day\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70ZDpp_kbusu"
   },
   "source": [
    "After that we handle the HHMM Strings and format them to also a datetime-format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBUP9bmJhVKg"
   },
   "outputs": [],
   "source": [
    "def format_timestamp(to_convert):\n",
    "    if pd.isna(to_convert):\n",
    "      return pd.NA\n",
    "    else:\n",
    "      if to_convert == \"2400\":\n",
    "        to_convert = \"0000\"\n",
    "        return datetime.time(int(to_convert[0:2]), int(to_convert[2:4]))\n",
    "      return datetime.time(int(to_convert[0:2]), int(to_convert[2:4]))\n",
    "      #to_convert = pd.to_datetime(to_convert.zfill(4), errors=\"coerce\", format=\"%H%M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qSutUUtcAhz"
   },
   "outputs": [],
   "source": [
    "flights_data[\"scheduled_departure\"] = flights_data[\"scheduled_departure\"].apply(format_timestamp)\n",
    "flights_data[\"departure_time\"] = flights_data[\"departure_time\"].apply(format_timestamp)\n",
    "flights_data[\"wheels_off\"] = flights_data[\"wheels_off\"].apply(format_timestamp)\n",
    "flights_data[\"wheels_on\"] = flights_data[\"wheels_on\"].apply(format_timestamp)\n",
    "flights_data[\"scheduled_arrival\"] = flights_data[\"scheduled_arrival\"].apply(format_timestamp)\n",
    "flights_data[\"arrival_time\"] = flights_data[\"arrival_time\"].apply(format_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpqNtrBnNEr2"
   },
   "source": [
    "Next we can add more columns to use later for the analysis.\n",
    "The `delay_difference` is the difference between the departure and arrival delay.\n",
    "The `cat`-suffix maps attributes with non-numeric types to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdNDfqx3NCJg"
   },
   "outputs": [],
   "source": [
    "flights_data[\"delay_difference\"] = flights_data.arrival_delay - flights_data.departure_delay\n",
    "flights_data['airline_cat']=flights_data['airline'].astype('category').cat.codes\n",
    "flights_data['origin_airport_cat']=flights_data['origin_airport'].astype('category').cat.codes\n",
    "flights_data['destination_airport_cat']=flights_data['destination_airport'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgPL_W8ZMIiq"
   },
   "source": [
    "# 4. Exploratory Data Analysis\n",
    "Exploratory Data Analysis (EDA) aims to make Data and its inherent patterns understandable for humans (by making pretty plots).\n",
    "We begin by looking at generally at all the Data. Afterwards we focus on airports and flights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5yvnU-8zfYv"
   },
   "source": [
    "The EDA of this project consists of three parts: A general EDA, an EDA in relationship with the airline data and a third one in relation to the airports' data.\n",
    "The questions /hypotheses which were created for and during the EDA are:\n",
    "- Where are the airports located on a map?\n",
    "- Which airport has the most departures / arrivals? Is one of the most visited airports a one-way airport?\n",
    "- Which airport has the most numbers delays?Â \n",
    "- Which airport has the most time of delay?\n",
    "- Does the number of flights correlate with the delay time? Is a high number of flights causing delays?\n",
    "- Which airlines have the highest delays?\n",
    "- What type of delays cause the most delay?\n",
    "- Can we predict a flights destination based on its attributes?\n",
    "- Can we predict the delay time based on its attributes?z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwVejln8XXlH"
   },
   "source": [
    "### 4.1 General EDA\n",
    "First we take a look at some general metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fnKthunLsco"
   },
   "outputs": [],
   "source": [
    "to_describe = [\"departure_delay\", \"arrival_delay\", \"scheduled_time\", \"elapsed_time\", \"air_time\", \"delay_difference\", \"distance\", 'cancelled', 'cancellation_reason',\n",
    "               'air_system_delay', 'security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay']\n",
    "flights_data[to_describe].describe().applymap(lambda x: f\"{x:.3f}\") # describe data with pretty print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBV-GrJGMUjy"
   },
   "source": [
    "todo insights to describe\n",
    "\n",
    "\n",
    "Next we can look at histograms made from the attributes of `flight_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCmn5bjePKfr"
   },
   "outputs": [],
   "source": [
    "flights_data.hist(figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZMxYEh6PN63"
   },
   "source": [
    "January and December have significantly more flights than the rest of the months.\n",
    "The last day of the month has more flight than the other days.\n",
    "There are fewer flights on Saturday.\n",
    "The duration of most flights is in between of 100 and 200 minutes.\n",
    "The duration of the air time of most flights is inbetween 0 and 166 minutes. Taking the general metrics account the interval is between 7 and 166 minutes.\n",
    "The travel distance of most flights is in between 0 and 1000 Miles. Taking the general metrics account the interval is between 21 and 1000 Miles.\n",
    "\n",
    "As next step we can look at the correlation between the attributes of `flight_data`. In order to achieve this, we use the pearson correlation and visualize the matrix as heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVQaQjacPsNF"
   },
   "outputs": [],
   "source": [
    "continuous_of_interest = [\"date\", \"day_of_week\", \"distance\",\"scheduled_time\",\"elapsed_time\", \"scheduled_departure\", \"departure_delay\",\"arrival_delay\", \"delay_difference\",\"airline_cat\", \"origin_airport_cat\", \"destination_airport_cat\"] # airport, airline\n",
    "f_corr, ax_corr = plt.subplots(figsize=(20, 12))\n",
    "corr = flights_data.loc[:, continuous_of_interest].corr(method=\"pearson\")\n",
    "hm_corr = sns.heatmap(round(corr,2), annot=True, ax=ax_corr, cmap=\"coolwarm\",fmt='.2f', linewidths=.05)\n",
    "f_corr.subplots_adjust(top=0.93)\n",
    "t= f_corr.suptitle('Attribute Pearson Correlation Heatmap', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CH2U24FZPse0"
   },
   "source": [
    "\n",
    "*   `distance`, `scheduled_time` and `elapsed_time` are all correlated with each other\n",
    "*   `departure_delay` and `arrival_delay` are correlated\n",
    "*   `origin_airport_cat` and `destination_airport_cat` are correlated\n",
    "*   `airline_cat` is negatively correlated with `distance`, `scheduled_time` and `elapsed_time`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnxX6nlKSlF8"
   },
   "source": [
    "### 4.2. Analysis of the Airport delays\n",
    "The general idea about this part of EDA is it to get an insight about delays in regard to the airports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGOyUG3iv2Sy"
   },
   "source": [
    "##### In order to get a first impression of the distribution how many flights are departed from each airport, I group and count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yC68rxqzS9kt"
   },
   "outputs": [],
   "source": [
    "flights_data.groupby(['origin_airport']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc368cA3wmna"
   },
   "source": [
    "##### Investigating flights with an unusual `origin_airport`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyBP_I9HYd06"
   },
   "source": [
    "We noticed that there are flights where the `origin_airport` is titled with a number instead of a three-lettered-code as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3Zew3yAYc4R"
   },
   "outputs": [],
   "source": [
    "number_of_flights_with_number_as_origin_airport = 0\n",
    "for i in range(len(flights_data.origin_airport)):\n",
    "  origin_airport_len = len(flights_data.origin_airport.loc[i]) if type(flights_data.origin_airport.loc[i]) == str else flights_data.origin_airport.loc[i]\n",
    "  if origin_airport_len > 3:\n",
    "    number_of_flights_with_number_as_origin_airport+=1\n",
    "print(number_of_flights_with_number_as_origin_airport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r24c_Hk2XSJA"
   },
   "outputs": [],
   "source": [
    "print(\"Amount of flights where the origin airport is 10135:\", len(flights_data[flights_data.origin_airport == 10135]))\n",
    "print(\"Amount of flights where the origin airport is 10136:\", len(flights_data[flights_data.origin_airport == 10136]))\n",
    "print(\"Amount of flights where the origin airport is 10140:\", len(flights_data[flights_data.origin_airport == 10140]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UuSoY-yRZio_"
   },
   "outputs": [],
   "source": [
    "flights_data[flights_data.origin_airport == 10140]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jybZaqKZkK4"
   },
   "source": [
    "When briefly looking into the flights, we noticed that all flights which have a numerical origin_airport take place in october."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nj13t9BaUJ0q"
   },
   "outputs": [],
   "source": [
    "flights_data[flights_data.month == 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OqCPKpDUGVy"
   },
   "source": [
    "What we find out is that the amount of flights with a numerical `origin_airport` is equal to the amount of flights in October. We assume that this is a data collection error or systematic error in the system where the data is collected.\n",
    "\n",
    "At the same time there seems to be no real hint how a numerical origin_airport value can be mapped to an `IATA_CODE`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XT_Ye_4axsbG"
   },
   "source": [
    "To deal with it, we are merging the `airports_data` and `flights_data`. This should remove the data, which can't be mapped to a \"properly\" collected airport.\n",
    "\n",
    "At the same time we can gain more readable information. We can't just see the three-lettered-code of an airport, we also look up its name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOMIUKVKxgFu"
   },
   "source": [
    "##### Merging flight data with airports data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "collapsed": true,
    "id": "uBnEwBYErPfN",
    "outputId": "4407eb1f-1800-489d-9890-3a53cd607bb2"
   },
   "outputs": [],
   "source": [
    "airports_flight_data = flights_data.merge(airports_data, left_on=\"origin_airport\", right_on=\"iata_code\")\n",
    "airports_flight_data = airports_flight_data.rename(columns={\"airport\": \"origin_airport_name\"})\n",
    "airports_flight_data = airports_flight_data.drop(columns = [\"iata_code\"])\n",
    "airports_flight_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WLKG0O9uC17"
   },
   "source": [
    "Next, we drop the attributes which aren't necessary for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ldy9AKTdKTZZ"
   },
   "outputs": [],
   "source": [
    "airports_flight_data_orig = airports_flight_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yifQVqOquQgM"
   },
   "outputs": [],
   "source": [
    "airports_flight_data = airports_flight_data.drop(columns = ['airline', 'flight_number', 'tail_number', 'elapsed_time', 'wheels_off', 'wheels_on', 'distance', 'taxi_in', 'taxi_out', 'day_of_week', 'air_time', 'country', 'state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HljOhs7h6uLe"
   },
   "source": [
    "##### We want to look at the question of which airports are the biggest in terms of the number of in-and-out-going traffic / flights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XvXd_a_RX8G"
   },
   "outputs": [],
   "source": [
    "number_of_flights_per_origin_airport = airports_flight_data.groupby(by='origin_airport').size()\n",
    "number_of_flights_per_origin_airport = number_of_flights_per_origin_airport.sort_values(ascending=False)\n",
    "\n",
    "number_of_flights_per_destination_airport = airports_flight_data.groupby(by='destination_airport').size()\n",
    "number_of_flights_per_destination_airport = number_of_flights_per_destination_airport.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZvPtK4Y5Ibs"
   },
   "outputs": [],
   "source": [
    "print('Top 10 destination airports:', number_of_flights_per_destination_airport.index[:10])\n",
    "print('Top 10 origin airports:', number_of_flights_per_origin_airport.index[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-jWmbaa5kN_"
   },
   "source": [
    "The order of the top 10 airports is identical in comparison of `destination_airport` and `origin_airport`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lvIyeDm3S4V"
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(figsize = (20,15))\n",
    "X = number_of_flights_per_origin_airport.index[:10]\n",
    "y_origin = number_of_flights_per_origin_airport.values[:10]\n",
    "y_dest = number_of_flights_per_destination_airport.values[:10]\n",
    "  \n",
    "X_axis = np.arange(10)\n",
    "  \n",
    "plt.bar(X_axis - 0.2, y_origin, 0.4, label = 'Origin')\n",
    "plt.bar(X_axis + 0.2, y_dest, 0.4, label = 'Destination')\n",
    "  \n",
    "plt.xticks(X_axis, X)\n",
    "plt.xlabel(\"Airport IATA Code\")\n",
    "plt.ylabel(\"Number of flights\")\n",
    "plt.title('Top 10 Airports with the most flights (without October)', fontsize=15)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSOp3DTY50fA"
   },
   "outputs": [],
   "source": [
    "airports_data[airports_data['iata_code'] == 'ATL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7OmInsM6h1s"
   },
   "outputs": [],
   "source": [
    "airports_data[airports_data['iata_code'] == 'ORD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21StbFrG6iSy"
   },
   "outputs": [],
   "source": [
    "airports_data[airports_data['iata_code'] == 'DFW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V0TAQ4ObcZU"
   },
   "source": [
    "The bar charts show the Top 10 Airports (Origin and Destination) with the most flights out of this dataset. The month October was excluded from this visualization due to the problem that it is different encoded. In both charts can be seen that the order of origin and destination airports are the same (sorted by the amount of flights). \n",
    "\n",
    "The top three airports with the most in-and-outgoing flight traffic are:\n",
    "- Hartsfield-Jackson Atlanta International\n",
    "- Chicago O'Hare International Airport\n",
    "- Dallas/Fort Worth International Airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRvTFygtc44i"
   },
   "source": [
    "##### Next, we want to investigate which airports have the most delays:\n",
    "To investigate this, we want to look at:\n",
    "1. the time of the flight delays\n",
    "2.  the number of flights with delays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTM4J1OLepfN"
   },
   "source": [
    "##### First investigation of the delay values:\n",
    "First of what can be noticed is that there are different kinds of delays:\n",
    "- `departure_delay`\n",
    "- `arrival_delay`\n",
    "- `air_system_delay`\n",
    "- `security_delay`\n",
    "- `airline_delay`\n",
    "- `late_aircraft_delay`\n",
    "- `weather_delay`\n",
    "\n",
    "At first glance on the NaN values at the beginning, we already saw that nearly every delay attribute had `NaN` values. Therefore, we first need to understand when those values occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "4RLs1pu0fZG_"
   },
   "outputs": [],
   "source": [
    "airports_flight_data[airports_flight_data['cancelled'] == 0].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ucdkA7TcfE86"
   },
   "outputs": [],
   "source": [
    "print('Number of cancelled flights:', len(airports_flight_data[airports_flight_data['cancelled'] == 1]))\n",
    "airports_flight_data[airports_flight_data['cancelled'] == 1].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0g8Qo_e7yKR"
   },
   "source": [
    "The first attribute (`departure_delay`) does never have a `NaN` value when a flight is not cancelled. When looking at the other attributes, they do have NaN values. Especially the attributes `air_system_delay`, `security_delay`, `airline_delay`, `late_aircraft_delay` and `weather_delay` have a huge amount of `NaN` value for not-cancelled flights. At first, an assumption was that delays of these types lead to an increased probability of cancellation. But when investigating the cancelled flights, every entry was a `NaN` value for those attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzRBiMYe_Hqg"
   },
   "source": [
    "##### Next we want to look at the different delay attributes and how they are related to each other:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jpAgc0L_o6r"
   },
   "source": [
    "Therefore, we looked at a row where the columns `air_system_delay`, `security_delay`, `airline_delay`, `late_aircraft_delay` and `weather_delay` are not `NaN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWUt4st-3bqv"
   },
   "outputs": [],
   "source": [
    "airports_flight_data.loc[25:35,['origin_airport','departure_delay', 'arrival_delay', 'security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DDQ7BzbAPNs"
   },
   "source": [
    "The following conclusion is only based on a brief look at the data.\n",
    "Our presumption is that the attributes `air_system_delay`, `security_delay`, `airline_delay`, `late_aircraft_delay` and `weather_delay` are a more detailed representation of the attribute `arrival_delay`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQwcPdevBikk"
   },
   "source": [
    "We chose to look only in the columns `air_system_delay`, `security_delay`, `airline_delay`, `late_aircraft_delay` and `weather_delay` due to the fact that the `arrival_delay` represents the net loss of time on a flight. Furthermore, we can get a more detailed view when looking at those attributes instead of the `departure_delay`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqKkUbw_CFZt"
   },
   "source": [
    "As previously stated that the `arrival_delay` is only a summarization of the more detailed attributes, we can also leave this out for the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bAEvw4c-UcI"
   },
   "source": [
    "#### 1. Investigation of the time of the flight delays per airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "819iHRECCdD4"
   },
   "source": [
    "For the calculation of delay time it is necessary to fill the `NaN` values of the attributes `air_system_delay`, `security_delay`, `airline_delay`, `late_aircraft_delay` and `weather_delay`. Otherwise mathematical operations like building the sum wouldn't be possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBymjhyi92Ud"
   },
   "source": [
    "##### NaN-fill of the airport_flight data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FO5OfzEThzho"
   },
   "source": [
    "This means that those values need to be transformed in order to use them for the second part of the question. We chose to fill those `NaN` values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXU282ogKKSO",
    "outputId": "22a04d8d-18aa-43d5-8dd5-5a9b9fe43de0"
   },
   "outputs": [],
   "source": [
    "airports_flight_data_na_filled_orig = airports_flight_data_orig.copy()\n",
    "airports_flight_data_na_filled_orig[['air_system_delay', 'security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay']] = airports_flight_data_na_filled_orig[['air_system_delay', 'security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay']].fillna(value=0)\n",
    "airports_flight_data_na_filled_orig.loc[:,['air_system_delay', 'security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "54xUprp60mps"
   },
   "outputs": [],
   "source": [
    "airports_flight_data_na_filled = airports_flight_data.copy()\n",
    "airports_flight_data_na_filled[['air_system_delay', 'security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay']] = airports_flight_data_na_filled[['air_system_delay', 'security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay']].fillna(value=0)\n",
    "airports_flight_data_na_filled.loc[:,['air_system_delay', 'security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qmj-hYNRGBwl"
   },
   "source": [
    "##### Investigating negative `arrival_delay`:\n",
    "We also noticed that a big amount of flights show a negative value for `arrival_delay`. In this part of the analysis we want only focus on the \"real\" delay time. Otherwise positive and negative values could cancel each other out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWrA46-AD9wC"
   },
   "outputs": [],
   "source": [
    "len(airports_flight_data_na_filled[airports_flight_data_na_filled['arrival_delay'] < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIba3Dt1HJl3"
   },
   "source": [
    "In total there are more than 3 million data entries having a negative `arrival_delay`. Therefore, the impact when not handling it, could be huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGpP-NjDWDIf"
   },
   "outputs": [],
   "source": [
    "airports_flight_data_na_filled.iloc[0][['arrival_delay', 'security_delay', 'air_system_delay', 'airline_delay', 'weather_delay']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbD3YtL1Wbc5"
   },
   "source": [
    "Fortunately, we found out that the detailed attributes are all set to zero if a flight is earlier than expected. That means, handling it is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wegmqCdDC2v2"
   },
   "source": [
    "##### Creating the summed delays grouped by origin airport:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7w33f8B6lFuF"
   },
   "outputs": [],
   "source": [
    "flight_delays_grouped_by_origin_airport_in_minutes = airports_flight_data_na_filled.loc[:,['origin_airport','air_system_delay', 'security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay']].groupby(by='origin_airport').sum()\n",
    "flight_delays_grouped_by_origin_airport_in_minutes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDguG96E-ysQ"
   },
   "source": [
    "It is already visible that the security delay and weather delay seem to be smaller than the other types of delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWg7kF5pXAi5"
   },
   "outputs": [],
   "source": [
    "airports_flights_delay_types = pd.DataFrame((airports_flight_data_na_filled.groupby([\"origin_airport\"])[\"air_system_delay\"].sum()/60).round(2))\n",
    "airports_flights_delay_types[\"security_delay\"] = pd.DataFrame((airports_flight_data_na_filled.groupby([\"origin_airport\"])[\"security_delay\"].sum()/60).round(2))\n",
    "airports_flights_delay_types[\"airline_delay\"] = pd.DataFrame((airports_flight_data_na_filled.groupby([\"origin_airport\"])[\"airline_delay\"].sum()/60).round(2))\n",
    "airports_flights_delay_types[\"late_aircraft_delay\"] = pd.DataFrame((airports_flight_data_na_filled.groupby([\"origin_airport\"])[\"late_aircraft_delay\"].sum()/60).round(2))\n",
    "airports_flights_delay_types[\"weather_delay\"] = pd.DataFrame((airports_flight_data_na_filled.groupby([\"origin_airport\"])[\"weather_delay\"].sum()/60).round(2))\n",
    "airports_flights_delay_types[\"sum\"] = airports_flights_delay_types[[\"air_system_delay\", \"security_delay\",\"airline_delay\", \"late_aircraft_delay\", \"weather_delay\"]].sum(axis=1)\n",
    "airports_flights_delay_types = airports_flights_delay_types.sort_values(\"sum\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWE0OYz1dz5d"
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "airports_flights_delay_sum = airports_flights_delay_types[\"sum\"]\n",
    "temp['security_delay_per'] = pd.DataFrame(((airports_flights_delay_types[\"security_delay\"] /airports_flights_delay_sum)*100).round(2))\n",
    "temp[\"air_system_delay_per\"] = pd.DataFrame(((airports_flights_delay_types[\"air_system_delay\"] /airports_flights_delay_sum)*100).round(2))\n",
    "temp[\"airline_delay_per\"] = pd.DataFrame(((airports_flights_delay_types[\"airline_delay\"] /airports_flights_delay_sum)*100).round(2))\n",
    "temp[\"late_aircraft_delay_per\"] = pd.DataFrame(((airports_flights_delay_types[\"late_aircraft_delay\"] /airports_flights_delay_sum)*100).round(2))\n",
    "temp[\"weather_delay_per\"] = pd.DataFrame(((airports_flights_delay_types[\"weather_delay\"] /airports_flights_delay_sum)*100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_D3hlCc2gZ2e"
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGzr9dt_d2Mw"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize = (20,10))\n",
    "ax[0].set(ylabel=\"Airport IATA Code\",\n",
    "       xlabel=\"Flight delay time in hours\")\n",
    "\n",
    "ax[0].set_title('Top 10 Origin Airports with most delay time in hours')\n",
    "\n",
    "ax[1].set(ylim=(-0.5, 10.5), ylabel=\"Airport IATA Code\",\n",
    "       xlabel=\"Flight delay time percentage\")\n",
    "ax[1].set_title('Top 10 Origin Airports with most delay time: percentual distribution')\n",
    "\n",
    "ax[0] = airports_flights_delay_types[['air_system_delay', 'security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay']].iloc[:10].plot.barh(stacked=True, ax=ax[0])\n",
    "ax[1] = temp[['air_system_delay_per', 'security_delay_per', 'airline_delay_per', 'late_aircraft_delay_per', 'weather_delay_per']].iloc[:10].plot(kind=\"barh\",stacked=True, ax=ax[1])\n",
    "plt.suptitle('Top 10 origin airports with the most delay time', fontsize= 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGNP1uDmaHfP"
   },
   "source": [
    "In every airport of the plot a big amount of delay time is caused by `airline_delay` and `late_aircraft_delay`. In contrast to that the `security_delay` time is just minimal. \n",
    "\n",
    "Comparing this rank order of the delay time to the plot with the largest amount of in- and outgoing flights, the ranking is about the same. In this plot (Top 10 origin airports with the most delay time), the airports `LGA` (LaGuardia Airport (Marine Air Terminal)) and `MCO` (Orlando International Airport) are ranked 9th and 10th, respectively. In contrast to the top 10 airports with the most flights, `PHX` (Phoenix Sky Harbor International Airport) and `MSP` (Minneapolis-Saint Paul International) are missing here.\n",
    "\n",
    "In addition, the rank order did change a little. Here is a table showing the Top-10 rank order of both plots:\n",
    "\n",
    "| Rank | Top 10 with most delay time | Top 10 with most flights |\n",
    "|------|-----------------------------|--------------------------|\n",
    "| 1    | ORD                         | ATL                      |\n",
    "| 2    | ATL                         | ORD                      |\n",
    "| 3    | DFW                         | DFW                      |\n",
    "| 4    | DEN                         | DEN                      |\n",
    "| 5    | LAX                         | LAX                      |\n",
    "| 6    | IAH                         | SFO                      |\n",
    "| 7    | SFO                         | PHX                      |\n",
    "| 8    | LAS                         | IAH                      |\n",
    "| 9    | LGA                         | LAS                      |\n",
    "| 10   | MCO                         | MSP                      |\n",
    "\n",
    "The similarity of these two diagrams can be explained by the fact that a higher number of flights also results in a higher total delay time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfPXxJDQva0M"
   },
   "source": [
    "##### Next, we want to look at the ratio between the delay time and number of flights. In this way, we can see what the average delay per flight is at an airport and whether it is similar to the number of flights plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Mw4_UwZw63j"
   },
   "outputs": [],
   "source": [
    "airports_delay_num_flights_df = airports_flights_delay_types.merge(number_of_flights_per_origin_airport.rename('number_of_flights'), left_index=True, right_index=True)\n",
    "airports_delay_num_flights_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bvlj4Tdx4D1"
   },
   "outputs": [],
   "source": [
    "temp2 = pd.DataFrame()\n",
    "number_of_flights = airports_delay_num_flights_df['number_of_flights']\n",
    "temp2['security_delay_ratio'] = pd.DataFrame(((airports_delay_num_flights_df[\"security_delay\"] /number_of_flights).round(2)))\n",
    "temp2[\"air_system_delay_ratio\"] = pd.DataFrame(((airports_delay_num_flights_df[\"air_system_delay\"] /number_of_flights).round(2)))\n",
    "temp2[\"airline_delay_ratio\"] = pd.DataFrame(((airports_delay_num_flights_df[\"airline_delay\"] /number_of_flights).round(2)))\n",
    "temp2[\"late_aircraft_delay_ratio\"] = pd.DataFrame(((airports_delay_num_flights_df[\"late_aircraft_delay\"] /number_of_flights).round(2)))\n",
    "temp2[\"weather_delay_ratio\"] = pd.DataFrame(((airports_delay_num_flights_df[\"weather_delay\"] /number_of_flights).round(2)))\n",
    "temp2[\"sum_delay_ratio\"] = pd.DataFrame(((airports_delay_num_flights_df[\"sum\"] /number_of_flights).round(2)))\n",
    "temp2 = temp2.sort_values('sum_delay_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44ZjFuyBz6lo"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (10,10))\n",
    "ax.set(ylabel=\"Airport IATA Code\",\n",
    "       xlabel=\"Mean flight delay time in minutes\")\n",
    "\n",
    "temp2[['air_system_delay_ratio', 'security_delay_ratio', 'airline_delay_ratio', 'late_aircraft_delay_ratio', 'weather_delay_ratio']].iloc[:10].plot.barh(stacked=True, ax=ax)\n",
    "plt.title('Top 10 origin airports with the highest delay time ratio', fontsize= 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4R36qjb9haP"
   },
   "outputs": [],
   "source": [
    "temp2.index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UzpaMqRp76-2"
   },
   "outputs": [],
   "source": [
    "highest_delay_ratio_airports_ranking_in_num_of_flights = airports_flight_data_na_filled.groupby('origin_airport').size()\n",
    "highest_delay_ratio_airports_ranking_in_num_of_flights = highest_delay_ratio_airports_ranking_in_num_of_flights.sort_values(ascending=False)\n",
    "highest_delay_ratio_airports_ranking_in_num_of_flights = highest_delay_ratio_airports_ranking_in_num_of_flights.reset_index()\n",
    "highest_delay_ratio_airports_ranking_in_num_of_flights = highest_delay_ratio_airports_ranking_in_num_of_flights[highest_delay_ratio_airports_ranking_in_num_of_flights.origin_airport.isin(temp2.index[:10])]\n",
    "highest_delay_ratio_airports_ranking_in_num_of_flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ja1giZlx-aMS"
   },
   "source": [
    "Summed Number of flights of the top 10 airports with the highest delay ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yq2ZuDXf-Cyc"
   },
   "outputs": [],
   "source": [
    "highest_delay_ratio_airports_ranking_in_num_of_flights[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Q-FQe0a-1ft"
   },
   "outputs": [],
   "source": [
    "airports_flight_data_na_filled.groupby('origin_airport').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spDHDgd62Ygr"
   },
   "outputs": [],
   "source": [
    "temp2_ri = temp2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2T-MQ9fo2c-L"
   },
   "outputs": [],
   "source": [
    "temp2_ri[temp2_ri['origin_airport'].isin(number_of_flights_per_origin_airport.index[:10])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmrABZd83JJu"
   },
   "source": [
    "The plot and table shows that none of airports out of the _Top 10 origin airports with the largest number of flights_ or _Top 10 origin airports with the most delay time_ are part of the _Top 10 origin airports with the highest delay time ratio_.\n",
    "\n",
    "Instead, the Top 3 airports of both the number of flights and as well the plot with the most delay time in total are ranked at:\n",
    "\n",
    "| origin_airport | Index of the delay time ratio DF |\n",
    "|----------------|----------------------------------|\n",
    "| ATL            | 256                              |\n",
    "| ORD            | 41                               |\n",
    "| DFW            | 117                              |\n",
    "\n",
    "It was shown that the ratio of the delay time per flight seems not to be strongly connected to the number of flights. But it needs to be considered that the airports with the highest delay ratio also do not have many registered flights. The summed number of flights of the top 10 airports with the highest delay ratio is 6706. Comparing this number to only the number of flights of ATL with 346.836, these 10 airports just registered about 1,9% of the flights.\n",
    "\n",
    "The conclusion that the number of flights and the delay ratio are not strongly connected is still valid when considering the index ranking,e.g. ATL 256 out of 322. Nevertheless, there are airports which have just a small amount of flights and are not a good representation. That is the reason to take this conclusion with caution. To back up this conclusion we want to look at the correlation between those variables in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FDGILTLyJVO"
   },
   "source": [
    "##### Looking at the correlation between the avg delay time per flight and number of flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LaYui1MyOJD"
   },
   "outputs": [],
   "source": [
    "correation_df_number_of_flights_avg_delay = temp2.merge(number_of_flights.rename('number_of_flights'), left_index=True, right_index=True)\n",
    "correation_df_number_of_flights_avg_delay = correation_df_number_of_flights_avg_delay.sort_values('number_of_flights', ascending=False)\n",
    "correation_df_number_of_flights_avg_delay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_eHrggSyQUU"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(correation_df_number_of_flights_avg_delay[['sum_delay_ratio', 'number_of_flights']].corr(), cmap=\"YlGnBu\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "024_-a8QySJ9"
   },
   "outputs": [],
   "source": [
    "sns.regplot(data=correation_df_number_of_flights_avg_delay, x='sum_delay_ratio', y='number_of_flights',\n",
    "                line_kws={\"color\": \"green\"},\n",
    "                order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r91LCjk0yUOq"
   },
   "source": [
    "The correlation matrix and scatter plot clearly shows that the correlation of these two variables is quite weak.\n",
    "\n",
    "Reflecting on the two initial questions:\n",
    "- Does the number of flights correlate with the delay time? \n",
    "- Is a high number of flights causing delays?\n",
    "\n",
    "There seems to be a correlation between number of flights and delay time. But when considering only the average delay time per flight, there is no pattern.\n",
    "That means that a high number of flights does not cause a delay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4bomI3N-hvQ"
   },
   "source": [
    "#### 2. Investigation of the number of flights with delays per airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WumxB0sWnECS"
   },
   "outputs": [],
   "source": [
    "number_of_flight_delays_grouped_by_origin_airport = airports_flight_data.loc[:,['origin_airport','security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay']].groupby(by='origin_airport').apply(lambda x: x.count())\n",
    "number_of_flight_delays_grouped_by_origin_airport = number_of_flight_delays_grouped_by_origin_airport.sort_values(ascending=False, by='security_delay')\n",
    "number_of_flight_delays_grouped_by_origin_airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzCXzn7K0Za0"
   },
   "source": [
    "When counting the number of the number of delays of each attribute, we have noticed that whenever one of those attributes has a delay, every other of these attributes has a value. If one of these hasn't a delay, its value is set to `0.0`. \n",
    "\n",
    "Due to the fact that the number of delays for each of these attributes is going to be the same, we are only plotting one of the attributes to represent the other delay attributes as well. We chose the attribute `security_delay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMv2ncyG6VFy"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "f, ax = plt.subplots(figsize = (15,15))\n",
    "sns.barplot(y=number_of_flight_delays_grouped_by_origin_airport.index, x=number_of_flight_delays_grouped_by_origin_airport.security_delay)\n",
    "ax.set(ylim=(-0.5, 10.5), ylabel=\"Airport IATA Code\",\n",
    "       xlabel=\"Number of flights with delay\")\n",
    "#ax.set_xticklabels(number_of_flights_per_origin_airport.index)\n",
    "for p in ax.patches:\n",
    "  ax.annotate(int(p.get_width()), (p.get_width()-5000, p.get_y()+0.35), fontsize=15)\n",
    "\n",
    "plt.title('Top 10 Origin Airports with the highest number of flight delays due to security / airline / late aircraft or weather')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fodBJOoqLWZ-"
   },
   "outputs": [],
   "source": [
    "security_flight_delays_grouped_by_origin_airport_in_minutes = flight_delays_grouped_by_origin_airport_in_minutes['security_delay'].sort_values(ascending=False)\n",
    "airline_flight_delays_grouped_by_origin_airport_in_minutes = flight_delays_grouped_by_origin_airport_in_minutes['airline_delay'].sort_values(ascending=False)\n",
    "late_aircraft_flight_delays_grouped_by_origin_airport_in_minutes = flight_delays_grouped_by_origin_airport_in_minutes['late_aircraft_delay'].sort_values(ascending=False)\n",
    "weather_flight_delays_grouped_by_origin_airport_in_minutes = flight_delays_grouped_by_origin_airport_in_minutes['weather_delay'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FARXbRqcTy8"
   },
   "source": [
    "#### 4.2.1 Geographical Airport Distribution\n",
    "1. Where are the airports located on the map?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwMmO6r6ca8c"
   },
   "outputs": [],
   "source": [
    "airportsMapData = airports_data\n",
    "airportsMapData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blqKYnQ3cdxD"
   },
   "outputs": [],
   "source": [
    "\n",
    "map = fl.Map(location=[40, -98], zoom_start=5)\n",
    "airportsMapData.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkLUEUcRci_a"
   },
   "outputs": [],
   "source": [
    "for airport in range(0, len(airportsMapData)):\n",
    "    fl.Marker([airportsMapData.iloc[airport][\"latitude\"], airportsMapData.iloc[airport][\"longitude\"]], popup=airportsMapData.iloc[airport][\"iata_code\"], tooltip=airportsMapData.iloc[airport][\"airport\"]).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39DapeSCDBDr"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9o0wH6zbSBV"
   },
   "source": [
    "### 4.3 Airline Flight delays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2x1nxvabgpy"
   },
   "outputs": [],
   "source": [
    "flights_data = flights_data.merge(airlines_data, left_on=\"airline\", right_on=\"iata_code\")\n",
    "flights_data = flights_data.rename(columns={\"airline_x\": \"airline_code\", \"airline_y\": \"airline_name\"})\n",
    "flights_data = flights_data.drop(columns = [\"iata_code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpqsSYx1cbdq"
   },
   "source": [
    "Since we want to analyze the delay, we drop every table that we don't need for the analysis. For this we focus on the actual departure times and not on the taxi and wheel times, since the departure time is that time a passenger cares about. We also drop the cancelled flights, since there are many null values for the delay (because the flight never departed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DEoq-RADcaqV"
   },
   "outputs": [],
   "source": [
    "flights_data_delay = flights_data.drop(columns= [\"day_of_week\", \"flight_number\", \"tail_number\", \n",
    "                            \"taxi_out\", \"wheels_off\",'air_time', 'distance',\n",
    "                            \"wheels_on\", \"taxi_in\"])\n",
    "flights_data_delay = flights_data_delay[flights_data_delay[\"cancelled\"] ==0]\n",
    "flights_data_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_qMmpYtciIl"
   },
   "source": [
    "In the next steps the describe function is used to plot some statistical values. At this point the `depature_delay` is used, since you can argue that the airline can influence the `arrival_delay` by e.g. adjusting the flight speed. This also explains a difference in these both values and why the `depature_delay` is used in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2Yc4DlIchjf"
   },
   "outputs": [],
   "source": [
    "statistical_values_delay = flights_data_delay[\"departure_delay\"].groupby(flights_data[\"airline_name\"]).describe()\n",
    "statistical_values_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjVKgMJLcl2p"
   },
   "source": [
    "First lets look at the number of flight by airlines ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoTEHKYgcny_"
   },
   "outputs": [],
   "source": [
    "sns.barplot(y=statistical_values_delay.index, x =\"count\", data = statistical_values_delay, order =statistical_values_delay.sort_values(\"count\").index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KebQijOcqzP"
   },
   "source": [
    "We can look at the mean of the delay to evaluate which airline has the most delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkJVO2HOcscB"
   },
   "outputs": [],
   "source": [
    "sns.barplot(y=statistical_values_delay.index, x =\"mean\", data = statistical_values_delay, order =statistical_values_delay.sort_values(\"mean\").index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xepoRsbctgh"
   },
   "source": [
    "The plot above shows the Airlines with the avg delay in min. The problem here now is, that if you look at the max values, there are some delays that are over a day long. Since this are still delays, we could split the delays into certain ranges. Since the avg delay is ~ 9min I would determine that as a short delay. After that you could argue that a delay up to an hour is a medium and over an hour could be described as a long delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AiEKvWjscvMa"
   },
   "outputs": [],
   "source": [
    "rangelist = [10,60]\n",
    "flights_data_delay[\"delay_range\"] =  pd.cut(flights_data_delay['departure_delay'], \n",
    "                              [-np.inf] + sorted(rangelist) + [np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5tDV4j1cwrH"
   },
   "outputs": [],
   "source": [
    "delay_ranges_airlines = flights_data_delay[[\"delay_range\", \"airline_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NIap8lzcyZX"
   },
   "outputs": [],
   "source": [
    "delay_range_count = delay_ranges_airlines.groupby(['delay_range', 'airline_name']).size().unstack(fill_value=0)\n",
    "delay_range_count = delay_range_count.T\n",
    "delay_range_count = delay_range_count.rename(columns={delay_range_count.columns[0]: \"<10\", delay_range_count.columns[1]: \"10-60\", delay_range_count.columns[2]: \">60\"})\n",
    "delay_range_count.plot(kind=\"bar\", title=\"Delay displayed in ranges (in minutes)\",stacked=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae05AP4Fc2I_"
   },
   "outputs": [],
   "source": [
    "delay_range_count[\"sum_delays\"] = delay_range_count[[\"<10\",\"10-60\", \">60\"]].sum(axis=1)\n",
    "delay_range_count[\"<10_in_per\"] = ((delay_range_count[\"<10\"] /delay_range_count[\"sum_delays\"])*100).round(2)\n",
    "delay_range_count[\"10-60_in_per\"] = ((delay_range_count[\"10-60\"] /delay_range_count[\"sum_delays\"])*100).round(2)\n",
    "delay_range_count[\">60_in_per\"] = ((delay_range_count[\">60\"] /delay_range_count[\"sum_delays\"])*100).round(2)\n",
    "\n",
    "delay_range_count_percent = delay_range_count.drop(columns=[\"<10\",\"10-60\", \">60\", \"sum_delays\"])\n",
    "delay_range_count_percent = delay_range_count_percent.sort_values(\"<10_in_per\")\n",
    "delay_range_count_percent.plot(kind=\"bar\", stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyp-L-q_c8Rf"
   },
   "source": [
    "This gives us some insights why the airlines haves the highest means. Spirit Airlines have ~10% of the flights with a delay of more than an hour and by this have the highest amount of long delays. On second place with the highest amount of long delays is Frontier Airlines Inc., shortly followed by United Airlines Inc and JetBlue Airways. One could argue that Shortwest Airlines Co. are not in the top five worst Airlines this time, since they manage to have only ~6% long delays even though they have the highest flight volume. Also, the comparison of some Airlines have to be viewed carefully, since the flight volume of e.g. Hawaiian Airlines Inc is ~90% less than the flight volume of Spirit Airlines.\n",
    "\n",
    "In the next step, the different type of delays get evaluated. To get an insight about we count the numbers of delay and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_VtH3G7c9v_"
   },
   "outputs": [],
   "source": [
    "flights_delay_types = pd.DataFrame((flights_data_delay.groupby([\"airline_name\"])[\"air_system_delay\"].sum()/60).round(2))\n",
    "flights_delay_types[\"security_delay\"] = pd.DataFrame((flights_data_delay.groupby([\"airline_name\"])[\"security_delay\"].sum()/60).round(2))\n",
    "flights_delay_types[\"airline_delay\"] = pd.DataFrame((flights_data_delay.groupby([\"airline_name\"])[\"airline_delay\"].sum()/60).round(2))\n",
    "flights_delay_types[\"late_aircraft_delay\"] = pd.DataFrame((flights_data_delay.groupby([\"airline_name\"])[\"late_aircraft_delay\"].sum()/60).round(2))\n",
    "flights_delay_types[\"weather_delay\"] = pd.DataFrame((flights_data_delay.groupby([\"airline_name\"])[\"weather_delay\"].sum()/60).round(2))\n",
    "flights_delay_types = flights_delay_types.sort_values(\"airline_delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dk25K7mXc_yX"
   },
   "outputs": [],
   "source": [
    "flights_delay_types.plot(kind=\"barh\", stacked=True, figsize=(7,5.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWAo1SdCdBS_"
   },
   "source": [
    "As you can see the most time of delays comes form the  late_aircraft_delay. Still you could argue that an aircraft can be late, because of every other type of delay, e.g. an aircraft is grounded because of the weather or a security reason and is scheduled to flight again shortly after landing, it would be late due to another issue. By that conclusion the reason for the most time of delay is because of the airline, shortly followed by air_system_delays. Surprisingly, the delays because of the weather are quite rare in comparison to the just mentioned delays. Security reasons seem to cause the least time for delay and are pretty rare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdJJoOQodCwG"
   },
   "outputs": [],
   "source": [
    "flights_delay_types[\"sum\"] = flights_delay_types[[\"air_system_delay\", \"security_delay\",\"airline_delay\", \"late_aircraft_delay\", \"weather_delay\"]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQyjMzSTdDtr"
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp = pd.DataFrame(((flights_delay_types[\"security_delay\"] /flights_delay_types[\"sum\"])*100).round(2))\n",
    "temp[\"air_system_delay_pre\"] = pd.DataFrame(((flights_delay_types[\"air_system_delay\"] /flights_delay_types[\"sum\"])*100).round(2))\n",
    "temp[\"airline_delay_pre\"] = pd.DataFrame(((flights_delay_types[\"airline_delay\"] /flights_delay_types[\"sum\"])*100).round(2))\n",
    "temp[\"late_aircraft_delay_pre\"] = pd.DataFrame(((flights_delay_types[\"late_aircraft_delay\"] /flights_delay_types[\"sum\"])*100).round(2))\n",
    "temp[\"weather_delay_pre\"] = pd.DataFrame(((flights_delay_types[\"weather_delay\"] /flights_delay_types[\"sum\"])*100).round(2))\n",
    "temp = temp.rename(columns={temp.columns[0]: \"security_delay_pre\"})\n",
    "temp.plot(kind=\"barh\",stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cw_SmlmQdGPk"
   },
   "source": [
    "As you can see, the plot represents that what was described in the previous cell, but this time its put in percentages values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpoHjwDAeEFd"
   },
   "source": [
    "### Conclusion about delays in relation to airlines\n",
    "\n",
    "The general idea about this part of EDA was to get an insight about delays in regard to the airlines. First, the `airline_name` gets added to the `flights_data`, because the name of the airline makes much more sense for displaying purposes. In the next step, columns that are not needed for the analysis are dropped and the `flights_data` get grouped by the `airline_name` to aggregate data based on the different airlines. \n",
    "\n",
    "The first thing displayed is the volume of the airlines. As shown in the plot, there is a huge difference in the volume between airlines. Still even *Virgin America* with the lowest value has more than ~60.000 flights on record, but in comparison to the flight volume over ~1.2 million from *Southwest Airlines Co.* it is small. This could be a factor in comparing the airlines with each other.\n",
    "\n",
    "In the next plot mean values of the `depature_delay` of the airlines are shown. The `depature_delay` is used and not the `arrival_delay` because the airline can influence the `arrival_delay` by e.g. increasing the flying speed or similar. Since we want to compare values, the `departure_delay` is used, since it is much harder for an airline to influence that. Based on this the airlines with the most delay are *Spirit Air Lines* with a mean value of ~16 minutes, *United Air Lines Inc.* with a little over 14 minutes and closely followed by *Frontier Airlines Inc.* with around 13 minutes.\n",
    "\n",
    "The problem with the mean values are, that some delays are over a day long, which could influence the mean pretty heavily, if there are more than just a few. To get a look at this, the delays are split into groups, defined as less than 10 minutes as a short delay, 10 to 60 minutes as a medium delay and more than 60 minutes as a long delay. To get a good overview of how many flights are delayed in the groups, the next plot shows the distribution of the delays in percentage. By this you can see how many of all flights had a short,medium or long delay grouped by the airlines. One could argue, that the airlines with the least short delays has the more medium and long delays. Looking at that, the worst airline is *Spirit Air Lines* with roughly 70% short delays, ~21% medium delays and nearly 10% long delays, followed by *United Air Lines* with around 72% short delays, 20% and around 8% long delays. On the third place of the worst airlines is *Frontier Airlines Inc.* with ~74% short delays, nearly 18% medium delays and 8% long delays. By looking at these both factors the airlines with the most delays based on the mean and distribution the duration of the delay are:\n",
    "1. Spirit Air Lines\n",
    "2. United Air Liens\n",
    "3. Frontier Air Lines Inc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2Fj0Gm1uaqj"
   },
   "source": [
    "# 5. Predicting flight delays with ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ-I8WmSugzc"
   },
   "source": [
    "Since the EDA focused on delays, the main goal of the ML model to implement should be to predict a delay. In this case the model should be able to predict the flight delay. After getting 3 weeks of training data, the model they should be able to predict the delays of the last week. The decision was made to take the *United Air Lines Inc.* because it's the one with the most flights on record from the top 3 most delayed airlines. The month August was randomly chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uK8UHIWuduG"
   },
   "outputs": [],
   "source": [
    "flights_data_swa = flights_data[flights_data[\"airline_name\"] == \"Southwest Airlines Co.\"]\n",
    "flights_data_to_predict = flights_data_swa.copy(deep=True)\n",
    "flights_data_to_predict = flights_data_to_predict[flights_data_to_predict[\"month\"] == 8]\n",
    "flights_data_to_predict = flights_data_to_predict[flights_data_to_predict[\"cancelled\"] == 0]\n",
    "flights_data_to_predict = flights_data_to_predict.reset_index()\n",
    "flights_data_to_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uw0f0RLJui-b"
   },
   "source": [
    "Drop unnecessary columns and columns with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OiO3bpuAukHj"
   },
   "outputs": [],
   "source": [
    "flights_data_to_predict = flights_data_to_predict.drop(columns = [\"airline_code\", \"diverted\", \"cancelled\",\n",
    "                                                                 \"cancellation_reason\", \"air_system_delay\",\n",
    "                                                                 \"security_delay\", \"airline_delay\", \"late_aircraft_delay\",\n",
    "                                                                 \"weather_delay\", \"airline_name\", \"arrival_delay\", \"index\",\n",
    "                                                                 \"elapsed_time\", \"air_time\", \"taxi_in\", \"delay_difference\"\n",
    "                                                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSV3POkhu5WD"
   },
   "outputs": [],
   "source": [
    "stat_predict = pd.DataFrame(flights_data_to_predict[\"departure_delay\"].describe())\n",
    "stat_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NM4rlaEsu_sn"
   },
   "outputs": [],
   "source": [
    "flights_data_to_predict[\"departure_delay\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EusJRe_vASz"
   },
   "source": [
    "To get more accurate results, it could be wise to filter out outliers. First idea was to only use the delays that are less than 60 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUFxzCXbvB2X"
   },
   "outputs": [],
   "source": [
    "stat_predict = pd.DataFrame(flights_data_to_predict[\"departure_delay\"][flights_data_to_predict[\"departure_delay\"]<60].describe())\n",
    "stat_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzQs7qQwvD3N"
   },
   "outputs": [],
   "source": [
    "flights_data_to_predict[\"departure_delay\"][flights_data_to_predict[\"departure_delay\"]<60].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClSv1pNOvFF9"
   },
   "source": [
    "By filtering the delays to under 60 minutes, we lose around 10% but on the other hand have a better distribution of the delays and probably get better prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gi0XYGKwvKBc"
   },
   "outputs": [],
   "source": [
    "flights_data_to_predict = flights_data_to_predict[flights_data_to_predict[\"departure_delay\"]<60]\n",
    "flights_data_to_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5mRwM9CmUOn"
   },
   "source": [
    "First we need to convert the strings into integer representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldF8tHDjmWaa"
   },
   "outputs": [],
   "source": [
    "string_columns = [\"tail_number\",\"origin_airport\",\"destination_airport\"] # \"airline_name\"\n",
    "for c in string_columns:\n",
    "    flights_data_to_predict[c] = pd.factorize(flights_data_to_predict[c])[0]\n",
    "flights_data_to_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yzr1j0VgmZw9"
   },
   "source": [
    "Handle dates for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAN9RfYPmb6x"
   },
   "outputs": [],
   "source": [
    "def convert_to_ordinal(timestamp):\n",
    "    return (timestamp.hour * 60 + timestamp.minute)*60 +timestamp.second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-dL2aYJmds4"
   },
   "source": [
    "drop empty values and format the rest of the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOn9pAKAmgcW"
   },
   "outputs": [],
   "source": [
    "date_columns = [\"scheduled_departure\", \"departure_time\", \"wheels_off\", \"wheels_on\", \"scheduled_arrival\", \"arrival_time\"]\n",
    "flights_data_to_predict = flights_data_to_predict[flights_data_to_predict[\"wheels_on\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mV43gsR7mhtV"
   },
   "outputs": [],
   "source": [
    "for c in date_columns:\n",
    "    print(type(flights_data_to_predict[c].iloc[0]))\n",
    "    flights_data_to_predict[c] = flights_data_to_predict[c].apply(convert_to_ordinal)\n",
    "flights_data_to_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3P54TF2umjFy"
   },
   "source": [
    "To evaluate the model later on the dataset is split into a training- (first 3 weeks of august) and a testset (last week of august). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYcs24eamkDd"
   },
   "outputs": [],
   "source": [
    "train = flights_data_to_predict[flights_data_to_predict[\"date\"].apply(lambda x:x.date()) < datetime.date(2015, 8, 23)]\n",
    "train = train.drop(columns=[\"date\"])\n",
    "test = flights_data_to_predict[flights_data_to_predict[\"date\"].apply(lambda x:x.date()) >= datetime.date(2015, 8, 23)]\n",
    "test = test.drop(columns=[\"date\"])\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cbSFUi7mlVr"
   },
   "source": [
    "One basic approach to predict values is to implement a Random Forest. In this case the sklearn RandomForestRegressor is used with 100 estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4VVJZ3kVGkm"
   },
   "outputs": [],
   "source": [
    "train_y = train[\"departure_delay\"]\n",
    "train_X = train.drop(columns=[\"departure_delay\"])\n",
    "test_y = test[\"departure_delay\"]\n",
    "test_X = test.drop(columns=[\"departure_delay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zn_eohD_mm3x"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "rf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZs4_w2xmud3"
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp9EjZWFmv74"
   },
   "source": [
    "Model assessment approach:\n",
    "In this section, the evaluation approach of this project is described. For both prediction\n",
    "cases, a model was trained based on prepared data sets. To evaluate the reliability of the\n",
    "trained models, the r2_score or the accuracy_score and mean_squared_error functions\n",
    "are used. The r2_score is suitable for regression model and returns a value between\n",
    "0 and 100%. The accuracy score is a classification score and returns a value between 0 and 100%.\n",
    "In both cases does a higher value represent a better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FeI59SDmxYC"
   },
   "outputs": [],
   "source": [
    "r2 = r2_score(test_y, predictions)\n",
    "mse = mean_squared_error(test_y, predictions)\n",
    "print(\"Accuracy for the model is\",(r2*100).round(2) , \"% with a Mean Squared Error of:\", mse)\n",
    "#0.9536189195181843 6.565784486314211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcCvqteumy_8"
   },
   "source": [
    "For comparison increase the estimators to 1000 and compare it with the first Random Forest with 100 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S422_Nqgm1vU"
   },
   "outputs": [],
   "source": [
    "rf_two = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf_two.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OX4fJy0zm3BZ"
   },
   "outputs": [],
   "source": [
    "predictions_two = rf_two.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7uQzjijJm3km"
   },
   "outputs": [],
   "source": [
    "r2_two = r2_score(test_y, predictions_two)\n",
    "mse_two = mean_squared_error(test_y, predictions_two)\n",
    "print(\"Accuracy for the model is\",(r2_two*100).round(2) , \"% with a Mean Squared Error of:\", mse_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnzzOWjNJ4fd"
   },
   "source": [
    "# 6. Prediction of the flights destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "K0nLZkjzJ7uX",
    "outputId": "2ac147d0-a77c-4712-ea3a-9da34693e8d1"
   },
   "outputs": [],
   "source": [
    "df = airports_flight_data_na_filled_orig[airports_flight_data_na_filled_orig['month'] == 8].copy()\n",
    "df.drop(inplace=True, columns=['year', 'day', 'latitude', 'longitude', 'city', 'origin_airport_cat', 'destination_airport_cat', 'origin_airport_name', 'airline_cat', 'tail_number', 'flight_number', 'cancelled', 'cancellation_reason','state', 'country', 'delay_difference', 'air_system_delay', 'security_delay', 'airline_delay', 'late_aircraft_delay', 'weather_delay', 'departure_time', 'arrival_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOd4k1MCLXRp"
   },
   "outputs": [],
   "source": [
    "def convert_to_ordinal(timestamp):\n",
    "    return (timestamp.hour * 60 + timestamp.minute)*60 +timestamp.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "jxujd0D9MVl2",
    "outputId": "f7b63729-41da-4df2-ecec-5950724dedf9"
   },
   "outputs": [],
   "source": [
    "date_columns = [\"scheduled_departure\", \"wheels_off\", \"wheels_on\", \"scheduled_arrival\"]\n",
    "df = df[df[\"wheels_on\"].notna()]\n",
    "\n",
    "for c in date_columns:\n",
    "    df[c] = df[c].apply(convert_to_ordinal)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWD4p2eFMhnw"
   },
   "outputs": [],
   "source": [
    "airports_data = airports_data.reset_index()\n",
    "df = df.merge(airports_data[['index', 'iata_code']], left_on='origin_airport', right_on='iata_code')\n",
    "df.rename(columns={'index': 'origin_airport_encoded'}, inplace=True)\n",
    "df.drop(inplace=True, columns='iata_code')\n",
    "df = df.merge(airports_data[['index', 'iata_code']], left_on='destination_airport', right_on='iata_code')\n",
    "df.rename(columns={'index': 'destination_airport_encoded'}, inplace=True)\n",
    "df.drop(inplace=True, columns='iata_code')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "EyB7JwCLMlPd",
    "outputId": "7cb33f31-a50d-4137-c1b1-1e39de97e574"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_50_airports_in_august = df.groupby(by='destination_airport').size().sort_values(ascending=False)[:50].index\n",
    "top_50_airports_in_august"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[df['origin_airport'].isin(top_50_airports_in_august)]\n",
    "df = df[df['destination_airport'].isin(top_50_airports_in_august)]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZwZwBsOM80f"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['scheduled_departure','departure_delay','taxi_out','wheels_off','scheduled_time','distance','wheels_on','taxi_in','scheduled_arrival','arrival_delay','diverted','origin_airport_encoded']], df['destination_airport_encoded'], test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiVISsopNqPu"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRobnHAgW8bQ"
   },
   "source": [
    "Model assessment approach:\n",
    "In this section, the evaluation approach of this project is described. For both prediction\n",
    "cases, a model was trained based on prepared data sets. To evaluate the reliability of the\n",
    "trained models, the r2_score or the accuracy_score and mean_squared_error functions\n",
    "are used. The r2_score is suitable for regression model and returns a value between\n",
    "0 and 100%. The accuracy score is a classification score and returns a value between 0 and 100%.\n",
    "In both cases does a higher value represent a better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RfKjMNLW3fa"
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Accuracy for the model is\",(acc*100).round(2) , \"% with a Mean Squared Error of:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SXSFt1gW0mH"
   },
   "source": [
    "For comparison increase the estimators to 1000 and compare it with the first Random Forest with 100 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-W1crR7kWwaw"
   },
   "outputs": [],
   "source": [
    "rf_two = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "rf_two.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_two = rf_two.predict(X_test)\n",
    "acc_two = accuracy_score(y_test, predictions_two)\n",
    "mse_two = mean_squared_error(y_test, predictions_two)\n",
    "\n",
    "print(\"Accuracy for the model is\",(acc_two*100).round(2) , \"% with a Mean Squared Error of:\", mse_two)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Evaluation of the results\n",
    "### Evaluation of the delay prediction\n",
    "A regression model was developed to predict delays based on a given subset of data.\n",
    "In the prepared evaluation setup, the r2_score and mean_squared_error were calculated.\n",
    "For this particular model the r2_score determines an accuracy of  98.81% and an\n",
    "MSE of around 1.417 which can be seen as a good value.\n",
    "\n",
    "Even though the model is already very good, the same procedure was repeated with\n",
    "    an n_estimator of 1000. This was done to test if the modelled could be improved by\n",
    "increasing the amount of decision trees. This was a success, but with little changes. This\n",
    "particular model achieved an improvement by 0.08% for the accuracy and the MSE was\n",
    "reduced by 0.09. This improvement does not impact the prediction too much, but still\n",
    "slightly enhanced the model, which concludes that a higher n_estimator can improve a\n",
    "random forest, even though the model is already good.\n",
    "\n",
    "In terms of the initial hypothesis it was shown that a flight delay can be predicted by its attributes.\n",
    "\n",
    "### Evaluation of the flight destination prediction.\n",
    "In order to predict the destination airport of a flight, a classification model was trained on a given subset of data.\n",
    "The data was divided into training and test data subsets with the train_test_split by sklearn.\n",
    "\n",
    "The evaluation scores for the destination airport prediction model shows an accuracy_score of 98,51% but at the same time an MSE score of 167,211. This seems like a high error value for the calculated accuracy. In total, it seems to be an accurate model.\n",
    "\n",
    "As a comparison the random forest classifier should also train with an n_estimators of 1000.\n",
    "The higher number of estimators results in an improvement in accuracy of 0,07%. At the same time the MSE was reduced by 8,031.\n",
    "\n",
    "Due to the fact that the MSE is a metric value where the models need to be compared, a high value does not represent a bad model. A possible explanation could be that the airports are numerical encoded and a wrong classification is weighted differently based on the classified airport.\n",
    "\n",
    "Regarding the hypothesis whether a flights destination can be predicted by its attributes, the result shows a good prediction score on the test data. This confirms the hypothesis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "2DPFIAZgS-Vk",
    "1zWYQpuyMeTb",
    "0FARXbRqcTy8",
    "m9o0wH6zbSBV"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
